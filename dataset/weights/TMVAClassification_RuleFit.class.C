// Class: ReadRuleFit
// Automatically generated by MethodBase::MakeClass
//

/* configuration options =====================================================

#GEN -*-*-*-*-*-*-*-*-*-*-*- general info -*-*-*-*-*-*-*-*-*-*-*-

Method         : RuleFit::RuleFit
TMVA Release   : 4.2.1         [262657]
ROOT Release   : 6.24/06       [399366]
Creator        : jvillami
Date           : Sun Feb  6 18:28:59 2022
Host           : Linux centos7-docker 4.18.0-305.12.1.el8_4.x86_64 #1 SMP Wed Aug 11 01:59:55 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux
Dir            : /eos/home-j/jvillami/SWAN_projects/Sklearn-BDT/ZBosonBDT
Training events: 2000
Analysis type  : [Classification]


#OPT -*-*-*-*-*-*-*-*-*-*-*-*- options -*-*-*-*-*-*-*-*-*-*-*-*-

# Set by User:
V: "False" [Verbose output (short form of "VerbosityLevel" below - overrides the latter one)]
H: "True" [Print method-specific help message]
GDTau: "-1.000000e+00" [Gradient-directed (GD) path: default fit cut-off]
GDTauPrec: "1.000000e-02" [GD path: precision of tau]
GDStep: "1.000000e-02" [GD path: step size]
GDNSteps: "10000" [GD path: number of steps]
GDErrScale: "1.020000e+00" [Stop scan when error > scale*errmin]
fEventsMin: "1.000000e-02" [Minimum fraction of events in a splittable node]
fEventsMax: "5.000000e-01" [Maximum fraction of events in a splittable node]
nTrees: "20" [Number of trees in forest.]
RuleMinDist: "1.000000e-03" [Minimum distance between rules]
MinImp: "1.000000e-03" [Minimum rule importance accepted]
Model: "modrulelinear" [Model to be used]
RuleFitModule: "rftmva" [Which RuleFit module to use]
# Default:
VerbosityLevel: "Default" [Verbosity level]
VarTransform: "None" [List of variable transformations performed before training, e.g., "D_Background,P_Signal,G,N_AllClasses" for: "Decorrelation, PCA-transformation, Gaussianisation, Normalisation, each for the given class of events ('AllClasses' denotes all events of all classes, if no class indication is given, 'All' is assumed)"]
CreateMVAPdfs: "False" [Create PDFs for classifier outputs (signal and background)]
IgnoreNegWeightsInTraining: "False" [Events with negative weights are ignored in the training (but are included for testing and performance evaluation)]
LinQuantile: "2.500000e-02" [Quantile of linear terms (removes outliers)]
GDPathEveFrac: "5.000000e-01" [Fraction of events used for the path search]
GDValidEveFrac: "5.000000e-01" [Fraction of events used for the validation]
ForestType: "adaboost" [Method to use for forest generation (AdaBoost or RandomForest)]
RFWorkDir: "./rulefit" [Friedman's RuleFit module (RFF): working dir]
RFNrules: "2000" [RFF: Mximum number of rules]
RFNendnodes: "4" [RFF: Average number of end nodes]
##


#VAR -*-*-*-*-*-*-*-*-*-*-*-* variables *-*-*-*-*-*-*-*-*-*-*-*-

NVar 3
mll                           mll                           mll                           mll                           units                             'F'    [4.65739965439,580.323913574]
lead                          lead                          lead                          lead                          units                             'F'    [25.1236438751,470.718536377]
sublead                       sublead                       sublead                       sublead                       units                             'F'    [7.02512645721,245.635665894]
NSpec 0


============================================================================ */

#include <array>
#include <vector>
#include <cmath>
#include <string>
#include <iostream>

#ifndef IClassifierReader__def
#define IClassifierReader__def

class IClassifierReader {

 public:

   // constructor
   IClassifierReader() : fStatusIsClean( true ) {}
   virtual ~IClassifierReader() {}

   // return classifier response
   virtual double GetMvaValue( const std::vector<double>& inputValues ) const = 0;

   // returns classifier status
   bool IsStatusClean() const { return fStatusIsClean; }

 protected:

   bool fStatusIsClean;
};

#endif

class ReadRuleFit : public IClassifierReader {

 public:

   // constructor
   ReadRuleFit( std::vector<std::string>& theInputVars )
      : IClassifierReader(),
        fClassName( "ReadRuleFit" ),
        fNvars( 3 )
   {
      // the training input variables
      const char* inputVars[] = { "mll", "lead", "sublead" };

      // sanity checks
      if (theInputVars.size() <= 0) {
         std::cout << "Problem in class \"" << fClassName << "\": empty input vector" << std::endl;
         fStatusIsClean = false;
      }

      if (theInputVars.size() != fNvars) {
         std::cout << "Problem in class \"" << fClassName << "\": mismatch in number of input values: "
                   << theInputVars.size() << " != " << fNvars << std::endl;
         fStatusIsClean = false;
      }

      // validate input variables
      for (size_t ivar = 0; ivar < theInputVars.size(); ivar++) {
         if (theInputVars[ivar] != inputVars[ivar]) {
            std::cout << "Problem in class \"" << fClassName << "\": mismatch in input variable names" << std::endl
                      << " for variable [" << ivar << "]: " << theInputVars[ivar].c_str() << " != " << inputVars[ivar] << std::endl;
            fStatusIsClean = false;
         }
      }

      // initialize min and max vectors (for normalisation)
      fVmin[0] = 0;
      fVmax[0] = 0;
      fVmin[1] = 0;
      fVmax[1] = 0;
      fVmin[2] = 0;
      fVmax[2] = 0;

      // initialize input variable types
      fType[0] = 'F';
      fType[1] = 'F';
      fType[2] = 'F';

      // initialize constants
      Initialize();

   }

   // destructor
   virtual ~ReadRuleFit() {
      Clear(); // method-specific
   }

   // the classifier response
   // "inputValues" is a vector of input values in the same order as the
   // variables given to the constructor
   double GetMvaValue( const std::vector<double>& inputValues ) const override;

 private:

   // method-specific destructor
   void Clear();

   // common member variables
   const char* fClassName;

   const size_t fNvars;
   size_t GetNvar()           const { return fNvars; }
   char   GetType( int ivar ) const { return fType[ivar]; }

   // normalisation of input variables
   double fVmin[3];
   double fVmax[3];
   double NormVariable( double x, double xmin, double xmax ) const {
      // normalise to output range: [-1, 1]
      return 2*(x - xmin)/(xmax - xmin) - 1.0;
   }

   // type of input variable: 'F' or 'I'
   char   fType[3];

   // initialize internal variables
   void Initialize();
   double GetMvaValue__( const std::vector<double>& inputValues ) const;

   // private members (method specific)
   // not implemented for class: "ReadRuleFit"
};
void   ReadRuleFit::Initialize(){}
void   ReadRuleFit::Clear(){}
double ReadRuleFit::GetMvaValue__( const std::vector<double>& inputValues ) const {
   double rval=-1.876967608;
   //
   // here follows all rules ordered in importance (most important first)
   // at the end of each line, the relative importance of the rule is given
   //
   if ((67.8063736<inputValues[0])&&(inputValues[0]<114.3081665)) rval+=0.9462377564;   // importance = 0.532
   if ((inputValues[1]<67.56125641)&&(26.37644196<inputValues[2])) rval+=0.4855645327;   // importance = 0.312
   if ((70.51803589<inputValues[0])&&(inputValues[1]<67.56125641)) rval+=0.472647557;   // importance = 0.299
   if ((inputValues[0]<114.3081665)&&(53.33810806<inputValues[1])) rval+=-0.3267034878;   // importance = 0.194
   if ((86.98943329<inputValues[0])&&(inputValues[0]<114.3081665)&&(inputValues[2]<30.42725563)) rval+=0.3953978309;   // importance = 0.175
   if ((86.98943329<inputValues[0])&&(inputValues[0]<114.3081665)&&(30.42725563<inputValues[2])) rval+=0.2123934622;   // importance = 0.143
   if ((84.83966827<inputValues[0])&&(inputValues[1]<67.56125641)&&(31.71192932<inputValues[2])&&(inputValues[2]<44.38570023)) rval+=0.2157688174;   // importance = 0.142
   if ((84.83966827<inputValues[0])&&(44.30897522<inputValues[1])&&(inputValues[1]<67.56125641)&&(35.31464767<inputValues[2])&&(inputValues[2]<44.38570023)) rval+=0.2302878253;   // importance = 0.124
   if ((inputValues[0]<86.89546967)&&(inputValues[2]<41.20772552)) rval+=0.1835567268;   // importance = 0.114
   if ((inputValues[1]<46.34244919)) rval+=0.157518431;   // importance = 0.106
   if ((29.74993896<inputValues[2])) rval+=0.1500953535;   // importance = 0.094
   if ((86.89546967<inputValues[0])&&(47.62171173<inputValues[1])) rval+=-0.1428868836;   // importance = 0.092
   if ((inputValues[2]<41.11234665)) rval+=0.153437926;   // importance = 0.091
   if ((88.42300415<inputValues[0])&&(inputValues[0]<91.88420868)&&(inputValues[1]<67.56125641)) rval+=0.100846119;   // importance = 0.058
   if ((36.23944473<inputValues[2])&&(inputValues[2]<41.11234665)) rval+=-0.08691450084;   // importance = 0.048
   if ((inputValues[1]<67.56125641)&&(inputValues[2]<26.37644196)) rval+=-0.08338441507;   // importance = 0.041
   if ((34.50462723<inputValues[1])&&(inputValues[1]<46.34244919)) rval+=0.0531716525;   // importance = 0.035
   if ((86.89546967<inputValues[0])) rval+=0.03860607326;   // importance = 0.024
   if ((67.56125641<inputValues[1])) rval+=-0.03881937666;   // importance = 0.021
   if ((inputValues[0]<86.89546967)) rval+=-0.03122210517;   // importance = 0.020
   if ((inputValues[0]<85.24990845)&&(inputValues[1]<67.56125641)) rval+=-0.02898479738;   // importance = 0.016
   if ((40.67238235<inputValues[1])&&(inputValues[2]<41.11234665)) rval+=-0.02380808165;   // importance = 0.016
   if ((inputValues[1]<46.34244919)&&(33.02446365<inputValues[2])&&(inputValues[2]<41.15967941)) rval+=0.0270942695;   // importance = 0.014
   if ((inputValues[0]<86.89546967)&&(41.20772552<inputValues[2])) rval+=-0.05095369551;   // importance = 0.009
   if ((38.61954117<inputValues[1])&&(inputValues[1]<67.56125641)&&(inputValues[2]<40.87940598)) rval+=-0.01252647206;   // importance = 0.008
   if ((46.34244919<inputValues[1])&&(29.79990387<inputValues[2])) rval+=0.004732687427;   // importance = 0.003
   if ((inputValues[0]<86.89546967)&&(47.62171173<inputValues[1])&&(37.39863586<inputValues[2])) rval+=-0.01472065777;   // importance = 0.003
   if ((inputValues[0]<86.89546967)&&(47.62171173<inputValues[1])&&(inputValues[2]<37.39863586)) rval+=-0.004784348818;   // importance = 0.002
   if ((inputValues[0]<84.83966827)&&(inputValues[1]<67.56125641)&&(40.09704208<inputValues[2])&&(inputValues[2]<44.38570023)) rval+=-0.02047252589;   // importance = 0.001
   if ((inputValues[0]<86.89546967)&&(inputValues[1]<47.62171173)&&(inputValues[2]<41.20772552)) rval+=-0.001895674528;   // importance = 0.001
   //
   // here follows all linear terms
   // at the end of each line, the relative importance of the term is given
   //
   rval+=0.001498672878*std::min( double(192.7277527), std::max( double(inputValues[0]), double(20.96602631)));   // importance = 0.064
   rval+=-0.02382420954*std::min( double(162.1718597), std::max( double(inputValues[1]), double(29.38170815)));   // importance = 1.000
   rval+=0.0225137006*std::min( double(76.73851013), std::max( double(inputValues[2]), double(9.089562416)));   // importance = 0.435
   return rval;
}
inline double ReadRuleFit::GetMvaValue( const std::vector<double>& inputValues ) const
{
   // classifier response value
   double retval = 0;

   // classifier response, sanity check first
   if (!IsStatusClean()) {
      std::cout << "Problem in class \"" << fClassName << "\": cannot return classifier response"
                << " because status is dirty" << std::endl;
   }
   else {
         retval = GetMvaValue__( inputValues );
   }

   return retval;
}
